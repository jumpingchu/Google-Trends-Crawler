{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Trends 網址結構"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://trends.google.com.tw/trends/api/dailytrends?hl=zh-TW&tz=-480&ed=20200714&geo=TW&ns=15\n",
    "    \n",
    "    https://trends.google.com.tw/trends/api/dailytrends?hl=zh-TW&tz=-480&ed=20200714&geo=JP&ns=15\n",
    "    \n",
    "    1. ed=YYYYMMDD\n",
    "    2. geo=TW / geo=JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import tqdm.notebook as tqdm\n",
    "import os\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理 \"相關查詢\" 欄位\n",
    "def relatedQueries_proc(target):\n",
    "    if target == []:\n",
    "        target = '---'\n",
    "    else:\n",
    "        result = ''\n",
    "        for relatedQuery in target:\n",
    "            target = result + relatedQuery['query'] + ' / '\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trends_crawler(str_date: str, country: str) -> pd.DataFrame:\n",
    "    url = f'https://trends.google.com.tw/trends/api/dailytrends?hl=zh-TW&tz=-480&geo={country}&ns=15&ed={str_date}'\n",
    "    resp = requests.get(url)\n",
    "\n",
    "    # 文字處理\n",
    "    df = pd.DataFrame(json.loads(re.sub(r'\\)\\]\\}\\',\\n', '', resp.text))['default']['trendingSearchesDays'][0]['trendingSearches'])\n",
    "\n",
    "    # 欄位處理\n",
    "    df = df.drop(columns='shareUrl')\n",
    "    df['title'] = df['title'].apply(lambda x: x['query'])\n",
    "    df['articles'] = df['articles'].apply(lambda x: x[0]['title'])\n",
    "    df['relatedQueries'] = df['relatedQueries'].apply(relatedQueries_proc)\n",
    "    try:\n",
    "        df['image'] = df['image'].apply(lambda x: x['newsUrl'])\n",
    "    except:\n",
    "        pass\n",
    "    df.columns = ['關鍵字', '搜尋筆數', '相關查詢', '文章連結', '相關文章']\n",
    "\n",
    "    # 欄位移動\n",
    "    col = '文章連結'\n",
    "    move = df.pop(col)\n",
    "    df.insert(4, col, move)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'trends_%s.csv' % datetime.now().strftime('%Y-%m-%d')\n",
    "# with open(filename, 'w', encoding='utf-8-sig') as f:\n",
    "#     df.to_csv(f, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 迴圈抓近一個月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import html.parser\n",
    "# base_url = 'https://trends.google.com.tw/trends/api/dailytrends?hl=zh-TW&tz=-480&geo=TW&ns=15&ed='\n",
    "# html.unescape('&tz=-480&geo=TW&ns=15&ed=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=29)\n",
    "str_end_date = datetime.strftime(end_date, '%Y%m%d')\n",
    "str_start_date = datetime.strftime(start_date, '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0413faffcff4fd1838c89d69f0ebbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm.tqdm((pd.date_range(start=start_date, end=end_date, freq='1D'))):\n",
    "    str_i_date = datetime.strftime(i, '%Y%m%d')\n",
    "    ndf = trends_crawler(str_i_date, 'TW')\n",
    "    ndf['date'] = str_i_date\n",
    "    with open(f'./data_tw/{str_i_date}.pkl', 'wb') as f:\n",
    "        ndf.to_pickle(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f521dcdc5c94ab0b3418e13b5d4d4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm.tqdm((pd.date_range(start=start_date, end=end_date, freq='1D'))):\n",
    "    str_i_date = datetime.strftime(i, '%Y%m%d')\n",
    "    ndf = trends_crawler(str_i_date, 'JP')\n",
    "    ndf['date'] = str_i_date\n",
    "    with open(f'./data_jp/{str_i_date}.pkl', 'wb') as f:\n",
    "        ndf.to_pickle(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 讀取檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw = []\n",
    "for file in os.listdir('data_tw'):\n",
    "    if 'pkl' in file:\n",
    "        df_file = pd.read_pickle('./data_tw/' + file)\n",
    "        df_tw.append(df_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新 TW 字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./keyword_tw.txt', 'r', encoding='utf8') as f:\n",
    "    kw_list = [kw.strip() for kw in f.readlines()]\n",
    "    \n",
    "new_kw = []\n",
    "for data in df_tw:\n",
    "    new_kw += [kw + '\\n' for kw in data['關鍵字'] if kw.strip() not in kw_list]\n",
    "\n",
    "with open('./keyword_tw.txt', 'a+', encoding='utf8') as f:\n",
    "    f.writelines(''.join(list(set(new_kw))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clubhouse 邀請碼\\n',\n",
       " '王祖賢\\n',\n",
       " '鄭家純\\n',\n",
       " '范綱皓\\n',\n",
       " '嚴長壽\\n',\n",
       " '石原聰美\\n',\n",
       " '防疫照顧假\\n',\n",
       " '飛機杯\\n',\n",
       " '趙英俊\\n',\n",
       " '李子柒\\n',\n",
       " '元晶\\n',\n",
       " '鳳山霸凌\\n',\n",
       " '角頭浪流連\\n',\n",
       " '蓋亞那\\n',\n",
       " '李婉鈺\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp = []\n",
    "for file in os.listdir('data_jp'):\n",
    "    if 'pkl' in file:\n",
    "        df_file = pd.read_pickle('./data_jp/' + file)\n",
    "        df_jp.append(df_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新 JP 字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./keyword_jp.txt', 'r', encoding='utf-8') as f:\n",
    "    kw_list = [kw.strip() for kw in f.readlines()]\n",
    "\n",
    "new_kw = []\n",
    "for data in df_jp:\n",
    "    new_kw += [kw + '\\n' for kw in data['關鍵字'] if kw.strip() not in kw_list]\n",
    "\n",
    "with open('./keyword_jp.txt', 'a+', encoding='utf8') as f:\n",
    "    f.writelines(''.join(list(set(new_kw))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['福岡 コロナ\\n',\n",
       " '吉川愛\\n',\n",
       " '南野拓実\\n',\n",
       " '豊田剛一郎\\n',\n",
       " 'たこやきレインボー\\n',\n",
       " 'メドレー\\n',\n",
       " 'COCOA\\n',\n",
       " '満島真之介\\n',\n",
       " '満島ひかり\\n',\n",
       " 'コロナワクチン\\n',\n",
       " 'タカノフルーツパーラー\\n',\n",
       " '榊原ゆい\\n',\n",
       " 'Redmi Note 9T\\n',\n",
       " '川上洋平\\n',\n",
       " '崎山蒼志\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
